{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn.sa.net/2025/03/04/PZ2iwmofMgNzjeG.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本原理很简单: 就是针对用户的问题, 利用R1这类推理模型强大的规划和识别能力, 持续不断的找出每一次迭代中的有用信息、识别缺失信息和无效信息, 直到找到一个满意的回答(条件:无法照出缺失信息)\n",
    "\n",
    "inspire by https://build.nvidia.com/langchain/structured-report-generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# model instance\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "r1_model = ChatOpenAI(\n",
    "    model=\"deepseek-r1\",\n",
    "    temperature=0.6,\n",
    "    api_key=os.getenv(\"QWEN_API_KEY\"),\n",
    "    base_url=os.getenv(\"QWEN_BASE_URL\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Prompts\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "class Prompts:\n",
    "    VALIDATE_RETRIEVAL = PromptTemplate(\n",
    "        input_variables=[\"retrieved_context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "        You are a retrieval validator.\n",
    "        You will be provided with a question and chunks of text that may or may not contain the answer to the question.\n",
    "        Your role is to carefully look through the chunks of text provide a JSON response with three fields:\n",
    "        1. status: whether the retrieved chunks contain the answer to the question.\n",
    "        - 'COMPLETE' if the retrieved chunks contain the answer to the question, 'INCOMPLETE' otherwise. Nothing else.\n",
    "        \n",
    "        2. useful_information: the useful information from the retrieved chunks. Be concise and direct.\n",
    "        - if there is no useful information, set this to an empty string.\n",
    "        \n",
    "        3. missing_information: the missing information that is needed to answer the question in full. Be concise and direct.\n",
    "        - if there is no missing information, set this to an empty string.\n",
    "        \n",
    "        Please provide your response as dictionary in the following format.\n",
    "\n",
    "        {{\"status\": \"<status>\",\n",
    "        \"useful_information\": \"<useful_information>\",\n",
    "        \"missing_information\": \"<missing_information>\"}}\n",
    "        \n",
    "        Here is an example of the response format:\n",
    "        \n",
    "        {{\"status\": \"COMPLETE\",\n",
    "        \"useful_information\": \"The capital city of Canada is Ottawa.\",\n",
    "        \"missing_information\": \"The capital city of Mexico\"}}\n",
    "    \n",
    "        Do not include any other text.\n",
    "        \n",
    "        Context: {retrieved_context}\n",
    "        \n",
    "        The Question: {question}\n",
    "        Response:\n",
    "        \"\"\"\n",
    "    )\n",
    "    ANSWER_QUESTION = PromptTemplate(\n",
    "        input_variables=[\"retrieved_context\", \"question\"],\n",
    "        template=\"\"\"\n",
    "        You are a question answering agent.\n",
    "        You will be provided with a question and chunks of text that contain the answer to the question.\n",
    "        Your role is to carefully look through the chunks of text and answer the question.\n",
    "        Provide a direct and concise answer based on the information provided.\n",
    "        Do not include any additional information or commentary.\n",
    "        \n",
    "        The Question: {question}\n",
    "        Context: {retrieved_context}\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator-Optimizer Workflow\n",
    "from langgraph.graph import END, StateGraph\n",
    "from typing_extensions import TypedDict\n",
    "from tavily import TavilyClient\n",
    "import json\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    retrieved_context: str\n",
    "    router_decision: str\n",
    "    answer_to_question: str\n",
    "    missing_information: str\n",
    "    reasoning: str\n",
    "    useful_information: str\n",
    "\n",
    "class QAAgent:\n",
    "    def __init__(self):\n",
    "        self.tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "        self.workflow = self.create_workflow()\n",
    "\n",
    "    def retrieve(self, state: GraphState):\n",
    "        print(\"\\n=== STEP 1: RETRIEVAL ===\")\n",
    "        question = state[\"question\"]\n",
    "        print(\"Searching for:\", question)\n",
    "        result = self.tavily_client.search(question, max_results=3)    \n",
    "        retrieved_context = \"\\n\".join([r[\"content\"] for r in result[\"results\"]])\n",
    "        print(\"Retrieved Context: \\n\", retrieved_context)\n",
    "        return {\"retrieved_context\": retrieved_context}\n",
    "\n",
    "    def validate_retrieval(self, state: GraphState):\n",
    "        print(\"\\n=== STEP 2: VALIDATION ===\")\n",
    "        question = state[\"question\"]\n",
    "        retrieved_context = state[\"retrieved_context\"]\n",
    "        \n",
    "        validation_chain = Prompts.VALIDATE_RETRIEVAL | r1_model\n",
    "        llm_output = validation_chain.invoke({\"retrieved_context\": retrieved_context, \"question\": question}).content\n",
    "        \n",
    "        if \"<think>\" in llm_output and \"</think>\" in llm_output:\n",
    "            reasoning = llm_output.split(\"<think>\")[1].split(\"</think>\")[0].strip()\n",
    "            response = llm_output.split(\"</think>\")[1].strip()\n",
    "        else:\n",
    "            reasoning = \"\"\n",
    "            response = llm_output.strip()  # 将整个输出当作 response\n",
    "\n",
    "        strcutured_response = json.loads(response)\n",
    "        \n",
    "        router_decision = strcutured_response[\"status\"]\n",
    "        missing_information = strcutured_response[\"missing_information\"]\n",
    "        useful_information = strcutured_response[\"useful_information\"]\n",
    "        print(\"router decision:\", router_decision)\n",
    "        print(\"missing information:\", missing_information)\n",
    "        print(\"useful information:\", useful_information)\n",
    "\n",
    "        if router_decision == \"INCOMPLETE\":\n",
    "            print(\"Missing Information:\", missing_information)\n",
    "\n",
    "        return {\"router_decision\": router_decision, \"retrieved_context\": retrieved_context, \"useful_information\": useful_information, \"missing_information\": missing_information, \"reasoning\": reasoning}\n",
    "\n",
    "    def answer(self, state: GraphState):\n",
    "        print(\"\\n=== STEP 3: ANSWERING ===\")\n",
    "        question = state[\"question\"]\n",
    "        context = state[\"retrieved_context\"]\n",
    "\n",
    "        answer_chain = Prompts.ANSWER_QUESTION | r1_model\n",
    "        llm_output = answer_chain.invoke({\"retrieved_context\": context, \"question\": question}).content\n",
    "        \n",
    "        # 检查 <think> 标签是否存在\n",
    "        if \"<think>\" in llm_output and \"</think>\" in llm_output:\n",
    "            reasoning = llm_output.split(\"<think>\")[1].split(\"</think>\")[0].strip()\n",
    "            answer = llm_output.split(\"</think>\")[1].strip()\n",
    "        else:\n",
    "            reasoning = \"\"\n",
    "            answer = llm_output.strip()  # 将整个输出当作 answer\n",
    "\n",
    "        return {\"answer_to_question\": answer}\n",
    "\n",
    "    def find_missing_information(self, state: GraphState):\n",
    "        print(\"\\n=== STEP 2b: FINDING MISSING INFORMATION ===\")\n",
    "        missing_information = state[\"missing_information\"]\n",
    "        print(\"Searching for:\", missing_information)\n",
    "        \n",
    "        tavily_query = self.tavily_client.search(missing_information, max_results=3)\n",
    "        previously_retrieved_useful_information = state[\"useful_information\"]\n",
    "        newly_retrieved_context = \"\\n\".join([r[\"content\"] for r in tavily_query[\"results\"]])\n",
    "        combined_context = f\"{previously_retrieved_useful_information}\\n{newly_retrieved_context}\"\n",
    "        print(\"newly retrieved context:\", newly_retrieved_context)\n",
    "        return {\"retrieved_context\": combined_context}\n",
    "\n",
    "    @staticmethod\n",
    "    def decide_route(state: GraphState):\n",
    "        return state[\"router_decision\"]\n",
    "\n",
    "\n",
    "    # def create_workflow(self):\n",
    "    #     workflow = StateGraph(GraphState)\n",
    "        \n",
    "    #     workflow.add_node(\"retrieve context\", self.retrieve)\n",
    "    #     workflow.add_node(\"answer\", self.answer)\n",
    "        \n",
    "    #     workflow.set_entry_point(\"retrieve context\")\n",
    "    #     workflow.add_edge(\"retrieve context\",\"answer\")\n",
    "    #     workflow.add_edge(\"answer\", END)\n",
    "    #     compiled_graph = workflow.compile()\n",
    "    #     compiled_graph.get_graph(xray=1).draw_mermaid_png(output_file_path=\"agent-architecture.png\")\n",
    "    #     return compiled_graph\n",
    "\n",
    "    def create_workflow(self):\n",
    "        workflow = StateGraph(GraphState)\n",
    "        \n",
    "        workflow.add_node(\"retrieve context\", self.retrieve)\n",
    "        workflow.add_node(\"is retrieved context complete?\", self.validate_retrieval)\n",
    "        workflow.add_node(\"answer\", self.answer)\n",
    "        workflow.add_node(\"find missing information\", self.find_missing_information)\n",
    "        \n",
    "        workflow.set_entry_point(\"retrieve context\")\n",
    "        workflow.add_edge(\"retrieve context\", \"is retrieved context complete?\")\n",
    "        \n",
    "        workflow.add_conditional_edges(\n",
    "            \"is retrieved context complete?\",\n",
    "            self.decide_route,\n",
    "            {\n",
    "                \"COMPLETE\": \"answer\",\n",
    "                \"INCOMPLETE\": \"find missing information\"\n",
    "            }\n",
    "        )\n",
    "        workflow.add_edge(\"find missing information\", \"is retrieved context complete?\")\n",
    "    \n",
    "        workflow.add_edge(\"answer\", END)\n",
    "        compiled_graph = workflow.compile()\n",
    "        compiled_graph.get_graph(xray=1).draw_mermaid_png(output_file_path=\"agent-architecture.png\")\n",
    "        return compiled_graph\n",
    "\n",
    "    def run(self, question: str):\n",
    "        result = self.workflow.invoke({\"question\": question})\n",
    "        return result[\"answer_to_question\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== STEP 1: RETRIEVAL ===\n",
      "Searching for: 告诉我什么NVIDIA 4090已经在中国被禁售了么? 香港可以买到4090么? 4090和A100在模型推理上性能相差很大么?\n",
      "Retrieved Context: \n",
      " 据业内人士称，只要品牌所属公司的主体在中国内地、港澳，就不能继续在国内生产和销售rtx 4090。 在未来一段时间内，中国玩家仍然能买到RTX 4090，但都是库存产品，尤其是在禁售前各厂商想尽办法囤积的， 而在这一批卖完之后，就没有了。\n",
      "据业内人士称，只要品牌所属公司的主体在中国内地、港澳，就不能继续在国内生产和销售rtx 4090。 理论上，nvidia和台系品牌可以向美国商务部申请\n",
      "快科技11月17日消息，据英伟达中国官网显示，rtx 4090信息已经被移除，不过除了这个型号，其余rtx 40系正常购买。截至笔者发稿前，英伟达中国官网\n",
      "\n",
      "=== STEP 2: VALIDATION ===\n",
      "router decision: INCOMPLETE\n",
      "missing information: 4090与A100在模型推理上的性能差异\n",
      "useful information: RTX 4090已被禁止在中国内地、港澳地区生产和销售，但库存产品仍可购买直至售完。英伟达中国官网已移除RTX 4090信息。\n",
      "Missing Information: 4090与A100在模型推理上的性能差异\n",
      "\n",
      "=== STEP 2b: FINDING MISSING INFORMATION ===\n",
      "Searching for: 4090与A100在模型推理上的性能差异\n",
      "newly retrieved context: 对比A100和4090：两者的区别以及适用点 自2022年年末英伟达发布4090芯片以来，这款产品凭借着其优异的性能迅速在科技界占据了一席之地。现如今，不论是在游戏体验、内容创作能力方面还是模型精度提升方面，4090都是一个绕不过去的名字。而A100作为早些发布的产品，其优异的能力和适配性已经为它打下了良好的口碑。RTX 4090芯片和A100芯片虽然都是高性能的GPU，但它们在设计理念、目标市场和性能特点上有着明显的区别，而本篇文章将简单概述两者的区别同时介绍一下二者的特性。 GPU 训练性能和成本对比 虽然A100被称为深度学习神器，但是不一定代表他的性能任何时候都超过其他显卡，A100对标的是RTX 3090，都是Ampere架构的，而RTX 4090作为RTX 3090的升级版，架构是Ada Lovelace，单卡性能至少提升60%以上，RTX 4090在理论上核心性能远强于A100，下面这2个参数对比图也可以很直观的看出2张卡的差距。 RTX 4090与A100的FP16性能比较 根据之前的讨论，RTX 4090的FP16性能约为82.58 Tflops，而A100的FP16性能可达约312 Tflops。不过，随后我们发现实际使用中4090的FP16性能接近于A100。这可能是因为不同的测试条件和使用场景会影响性能测量，或者由于不同的硬件版本和配置。 从理论规格上看，A100确实在FP16上显示出更高的性能，但实际应用性能可能会有所不同，取决于具体任务和软件优化。 结论 既然 4090 单卡训练的性价比这么高，为啥不能用来做大模型训练呢？抛开不允许游戏显卡用于数据中心这样的许可证约束不谈，从技术上讲，根本原因是大模型训练需要高性能的通信。在大模型训练方面，A100比4090表现的更加优秀，但是在推理（inference/serving）方面，选择用 4090 芯片不仅可行，在性价比上还能比H100 稍高。而如果4090芯片对其进行极致优化，其性价比甚至可以达到 H100芯片 的 2 倍。 事实上，H100/A100 和 4090 最大的区别就在通信和内存上，算力差距不大。 在这小编向大家推荐一款来自UCloud优刻得的一款4090云服务器，相比较于市面上的一些GPU共享算力平台的资源，不仅价格实惠，性价比高，性能强劲 的同时还拥有独立IP、预装主流大模型及环境镜像，支持7X24的小时的售后服务。同时，UCloud还推出了9.9元/天的4090特惠，方便大家体验使用 价格非常香，可以放心上车！ 高性价比GPU算力：https://www.ucloud.cn/site/active/gpu.html?ytag=gpu_wenzhang_0624_shemei 立减 ¥ 热门文章 分类专栏 最新评论 芋头圆生煎:  23年是发布会时间，openAI宣布有这个功能；24年应该是用户真正可以用的时间吧 地狱在人间:  怎么修改内置的向量模型，text2vec还是效果差点 码农小筑:  这篇文章介绍的技术很新颖，用AI从截图生成代码，对前端程序员确实是个大帮助。通过Python结合多个API实现图像到代码的转换，步骤清晰，让人眼前一亮。期待更多实际应用案例分享。 weixin_44283150:  你的ai不太行啊，我为什么同样的问题不是这个回答。 征途黯然.:  真的很出色，HelloGPT4o文章非常精彩。 最新文章 目录 目录 分类专栏 目录 请填写红包祝福语或标题 红包个数最小为10个 红包金额最低5元 抵扣说明： 1.余额是钱包充值的虚拟货币，按照1:1的比例进行支付金额的抵扣。 2.余额无法直接购买下载，可以购买VIP、付费专栏及课程。\n",
      "根据上述的表格数据分析，A100在多个核心性能指标上显著超越4090，因此，它更适合作为大型模型训练的优选显卡。 大模型训练所需算力计算\n",
      "A100 和 4090 傻傻分不清？一文告诉你训练卡和推理卡的区别 - 知乎 切换模式 写文章 登录/注册 A100 和 4090 傻傻分不清？一文告诉你训练卡和推理卡的区别 知白 新时代互联网农名工，公众号:AI探索者知白 最近两天发现有读者问我，他想自己本地玩 Stable Diffusion 需要买哪种显卡？网上说的 A100 又是用于做什么？ 其实训练卡和推理卡它们在设计和性能上有着明显的差异，以适应不同的计算需求。 本文我将探讨这两种显卡的主要区别，并解释它们各自的优势和应用场景。 大模型训练卡：厨房中的大厨 想象一下，一位大厨在厨房里忙碌着，他需要准备一道复杂的菜肴。这就像训练型显卡在深度学习模型训练过程中的角色。 大厨需要尝试不同的食材组合，调整烹饪时间和温度，以找到最佳的口味平衡。这个过程需要大量的尝试和错误，就像训练模型时需要大量的数据和计算资源。 特点 高浮点运算能力：大厨需要精确控制火候和时间，这就像显卡需要强大的计算能力来处理复杂的数学运算。 大显存：大厨需要足够的空间来准备和存储各种食材，这对应于显卡需要大显存来存储大量数据和模型参数。 高带宽：大厨在烹饪过程中需要快速地取用食材，这类似于显卡需要高内存带宽来快速读取和写入数据。 价格 训练卡目前主要是以英伟达的 H100/H800/A100/A800 几种型号为主，目前国内价格在 10-30 万元每张居多。 逻辑推理卡：餐厅中的服务员 现在，想象一下服务员在餐厅中为顾客提供服务。一旦菜肴准备好，服务员就会迅速地将其送到顾客面前，并确保顾客的用餐体验流畅。 这就像推理型显卡在模型部署阶段的角色，它需要快速、准确地处理顾客（数据）的请求。 特点 优化的计算单元：服务员经过训练，能够迅速响应顾客的需求，这就像显卡针对推理任务优化的计算单元。 低精度运算：服务员可能不需要知道菜肴的详细制作过程，只需要知道如何正确地呈现给顾客，这对应于显卡在推理时可以容忍一定程度的精度损失。 成本效益：服务员的工作成本相对较低，这类似于推理型显卡在成本和功耗上的优化。 并行处理能力：服务员可以同时为多位顾客服务，这就像显卡能够同时处理多个推理任务。 价格 推理卡常见的有 4060/4090/3060/3080/3090 等型号，价格在几千到两万左右不等。 总结 总得来说：推理可以用训练卡，训练不可以用推理卡。 训练型显卡：适用于研究和开发环境，特别是在需要大量数据和复杂模型的场景，如图像识别、自然语言处理等。   推理型显卡：适用于生产环境，尤其是在需要快速响应和高吞吐量的在线服务中，如实时视频分析、推荐系统等。   看到这里知道自己要购买哪种显卡了嘛？具体型号根据大家的经济条件来选择。 发布于 2024-03-08 20:52・IP 属地浙江 A100服务器 RTX 4090 ​赞同 68​​16 条评论 ​分享 ​喜欢​收藏​申请转载\n",
      "\n",
      "=== STEP 2: VALIDATION ===\n",
      "router decision: COMPLETE\n",
      "missing information: \n",
      "useful information: RTX 4090已被禁止在中国内地、港澳地区生产和销售，但库存产品仍可购买直至售完。香港属于禁售区域但可购买库存。在模型推理方面，4090与A100算力差距不大，主要区别在于通信和内存；4090经过极致优化后推理性价比可达H100的2倍。\n",
      "\n",
      "=== STEP 3: ANSWERING ===\n",
      "NVIDIA 4090已在中国内地及港澳地区禁售，但库存仍可购买。香港属于禁售区域，但可能有库存销售。4090在模型推理性能上与A100接近，且性价比更高。\n"
     ]
    }
   ],
   "source": [
    "agent = QAAgent()\n",
    "answer = agent.run(\"告诉我什么NVIDIA 4090已经在中国被禁售了么? 香港可以买到4090么? 4090和A100在模型推理上性能相差很大么?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
